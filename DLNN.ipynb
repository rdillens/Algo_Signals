{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\r\n",
    "from pathlib import Path\r\n",
    "import tensorflow as tf\r\n",
    "from tensorflow.keras.layers import Dense\r\n",
    "from tensorflow.keras.models import Sequential\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\r\n",
    "import sqlalchemy\r\n",
    "import h5py"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "db_connection_string = 'sqlite:///./Resources/product.db'\r\n",
    "engine  = sqlalchemy.create_engine(db_connection_string)\r\n",
    "\r\n",
    "inspector = sqlalchemy.inspect(engine)\r\n",
    "table_names = inspector.get_table_names()\r\n",
    "print(table_names)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['AAPL_1_Day_Candles', 'AAPL_1_Min_Candles', 'AAPL_Indicators', 'AAPL_Info']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "ticker = 'AAPL'\r\n",
    "indicators_df = pd.read_sql_table(ticker + '_Indicators', con=engine, index_col='Datetime')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "## Prepare the data to be used on a neural network model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "print(indicators_df.head())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                        Open     High      Low    Close  Volume  CDLBELTHOLD  \\\n",
      "Datetime                                                                       \n",
      "2021-09-03 14:26:00  154.355  154.355  154.245  154.250  158378            0   \n",
      "2021-09-03 14:27:00  154.250  154.380  154.250  154.300  239650            0   \n",
      "2021-09-03 14:28:00  154.305  154.310  154.270  154.285   55602            0   \n",
      "2021-09-03 14:29:00  154.280  154.285  154.230  154.245   79606            0   \n",
      "2021-09-03 14:30:00  154.250  154.290  154.240  154.280  100991            0   \n",
      "\n",
      "                     CDLBREAKAWAY  CDLDOJISTAR  CDLLADDERBOTTOM  Trade Signal  \n",
      "Datetime                                                                       \n",
      "2021-09-03 14:26:00             0            0                0           0.0  \n",
      "2021-09-03 14:27:00             0            0                0           0.0  \n",
      "2021-09-03 14:28:00             0            0                0           0.0  \n",
      "2021-09-03 14:29:00             0            0                0           0.0  \n",
      "2021-09-03 14:30:00             0            0                0           0.0  \n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# Review the data types associated with the columns\r\n",
    "indicators_df.dtypes"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Open               float64\n",
       "High               float64\n",
       "Low                float64\n",
       "Close              float64\n",
       "Volume               int64\n",
       "CDLBELTHOLD          int64\n",
       "CDLBREAKAWAY         int64\n",
       "CDLDOJISTAR          int64\n",
       "CDLLADDERBOTTOM      int64\n",
       "Trade Signal       float64\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "display(indicators_df['Trade Signal'].value_counts())"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       " 0.0    10956\n",
       " 1.0     1957\n",
       "-1.0     1924\n",
       "Name: Trade Signal, dtype: int64"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 5: Using the preprocessed data, create the features (`X`) and target (`y`) datasets. The target dataset should be defined by the preprocessed DataFrame column “IS_SUCCESSFUL”. The remaining columns should define the features dataset. \n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 3: Encode the dataset’s categorical variables using `OneHotEncoder`, and then place the encoded variables into a new DataFrame."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# Create a list of categorical variables \r\n",
    "categorical_variables = ['Trade Signal']\r\n",
    "\r\n",
    "# Display the categorical variables list\r\n",
    "display(categorical_variables)"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "['Trade Signal']"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# Create a OneHotEncoder instance\r\n",
    "enc = OneHotEncoder(sparse=False)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# Encode the categorcal variables using OneHotEncoder\r\n",
    "encoded_data = enc.fit_transform(indicators_df[categorical_variables])\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# Create a DataFrame with the encoded variables\r\n",
    "encoded_df = pd.DataFrame(\r\n",
    "    encoded_data,\r\n",
    "    columns = enc.get_feature_names(categorical_variables)\r\n",
    ")\r\n",
    "# Review the DataFrame\r\n",
    "display(encoded_df.head(10))"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trade Signal_-1.0</th>\n",
       "      <th>Trade Signal_0.0</th>\n",
       "      <th>Trade Signal_1.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Trade Signal_-1.0  Trade Signal_0.0  Trade Signal_1.0\n",
       "0                0.0               1.0               0.0\n",
       "1                0.0               1.0               0.0\n",
       "2                0.0               1.0               0.0\n",
       "3                0.0               1.0               0.0\n",
       "4                0.0               1.0               0.0\n",
       "5                0.0               1.0               0.0\n",
       "6                0.0               1.0               0.0\n",
       "7                0.0               1.0               0.0\n",
       "8                0.0               1.0               0.0\n",
       "9                0.0               1.0               0.0"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "encoded_df.rename(columns={'Trade Signal_-1.0': 'Bearish', 'Trade Signal_0.0': 'None', 'Trade Signal_1.0':'Bullsih'}, inplace=True)\r\n",
    "encoded_df.drop(columns='None', inplace=True)\r\n",
    "print(encoded_df.head())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "   Bearish  Bullsih\n",
      "0      0.0      0.0\n",
      "1      0.0      0.0\n",
      "2      0.0      0.0\n",
      "3      0.0      0.0\n",
      "4      0.0      0.0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 4: Add the original DataFrame’s numerical variables to the DataFrame containing the encoded variables.\n",
    "\n",
    "> **Note** To complete this step, you will employ the Pandas `concat()` function that was introduced earlier in this course. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# Define the target set y using the IS_SUCCESSFUL column\r\n",
    "y = encoded_df.copy()\r\n",
    "\r\n",
    "# Display a sample of y\r\n",
    "display(y.head())"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bearish</th>\n",
       "      <th>Bullsih</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Bearish  Bullsih\n",
       "0      0.0      0.0\n",
       "1      0.0      0.0\n",
       "2      0.0      0.0\n",
       "3      0.0      0.0\n",
       "4      0.0      0.0"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# Define features set X by selecting all columns but IS_SUCCESSFUL\r\n",
    "X = indicators_df.drop(columns=['Trade Signal'])\r\n",
    "\r\n",
    "# Review the features DataFrame\r\n",
    "display(X.head())"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>CDLBELTHOLD</th>\n",
       "      <th>CDLBREAKAWAY</th>\n",
       "      <th>CDLDOJISTAR</th>\n",
       "      <th>CDLLADDERBOTTOM</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-09-03 14:26:00</th>\n",
       "      <td>154.355</td>\n",
       "      <td>154.355</td>\n",
       "      <td>154.245</td>\n",
       "      <td>154.250</td>\n",
       "      <td>158378</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-03 14:27:00</th>\n",
       "      <td>154.250</td>\n",
       "      <td>154.380</td>\n",
       "      <td>154.250</td>\n",
       "      <td>154.300</td>\n",
       "      <td>239650</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-03 14:28:00</th>\n",
       "      <td>154.305</td>\n",
       "      <td>154.310</td>\n",
       "      <td>154.270</td>\n",
       "      <td>154.285</td>\n",
       "      <td>55602</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-03 14:29:00</th>\n",
       "      <td>154.280</td>\n",
       "      <td>154.285</td>\n",
       "      <td>154.230</td>\n",
       "      <td>154.245</td>\n",
       "      <td>79606</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-03 14:30:00</th>\n",
       "      <td>154.250</td>\n",
       "      <td>154.290</td>\n",
       "      <td>154.240</td>\n",
       "      <td>154.280</td>\n",
       "      <td>100991</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Open     High      Low    Close  Volume  CDLBELTHOLD  \\\n",
       "Datetime                                                                       \n",
       "2021-09-03 14:26:00  154.355  154.355  154.245  154.250  158378            0   \n",
       "2021-09-03 14:27:00  154.250  154.380  154.250  154.300  239650            0   \n",
       "2021-09-03 14:28:00  154.305  154.310  154.270  154.285   55602            0   \n",
       "2021-09-03 14:29:00  154.280  154.285  154.230  154.245   79606            0   \n",
       "2021-09-03 14:30:00  154.250  154.290  154.240  154.280  100991            0   \n",
       "\n",
       "                     CDLBREAKAWAY  CDLDOJISTAR  CDLLADDERBOTTOM  \n",
       "Datetime                                                         \n",
       "2021-09-03 14:26:00             0            0                0  \n",
       "2021-09-03 14:27:00             0            0                0  \n",
       "2021-09-03 14:28:00             0            0                0  \n",
       "2021-09-03 14:29:00             0            0                0  \n",
       "2021-09-03 14:30:00             0            0                0  "
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 6: Split the features and target sets into training and testing datasets.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# Split the preprocessed data into a training and testing dataset\r\n",
    "# Assign the function a random_state equal to 1\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 7: Use scikit-learn's `StandardScaler` to scale the features data."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "# Create a StandardScaler instance\r\n",
    "scaler = StandardScaler()\r\n",
    "\r\n",
    "# Fit the scaler to the features training dataset\r\n",
    "X_scaler = scaler.fit(X_train)\r\n",
    "\r\n",
    "# Fit the scaler to the features training dataset\r\n",
    "X_train_scaled = X_scaler.transform(X_train)\r\n",
    "X_test_scaled = X_scaler.transform(X_test)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "## Compile and Evaluate a Binary Classification Model Using a Neural Network"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 1: Create a deep neural network by assigning the number of input features, the number of layers, and the number of neurons on each layer using Tensorflow’s Keras.\n",
    "\n",
    "> **Hint** You can start with a two-layer deep neural network model that uses the `relu` activation function for both layers.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "# Define the the number of inputs (features) to the model\r\n",
    "number_input_features = len(list(X.columns))\r\n",
    "# Review the number of features\r\n",
    "number_input_features\r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "# Define the number of neurons in the output layer\r\n",
    "number_output_neurons = 2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "# Define the number of hidden nodes for the first hidden layer\r\n",
    "hidden_nodes_layer1 =  int(round((number_input_features + number_output_neurons)/2, 0))\r\n",
    "# Review the number hidden nodes in the first layer\r\n",
    "hidden_nodes_layer1\r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "# Define the number of hidden nodes for the second hidden layer\r\n",
    "hidden_nodes_layer2 =  int(round((hidden_nodes_layer1 + number_output_neurons)/2, 0))\r\n",
    "\r\n",
    "# Review the number hidden nodes in the second layer\r\n",
    "hidden_nodes_layer2\r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "# Create the Sequential model instance\r\n",
    "nn = Sequential()\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "# Add the first hidden layer\r\n",
    "nn.add(Dense(units=hidden_nodes_layer1, activation=\"relu\", input_dim=number_input_features))\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "# Add the second hidden layer\r\n",
    "nn.add(Dense(units=hidden_nodes_layer2, activation=\"relu\"))\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "# Add the output layer to the model specifying the number of output neurons and activation function\r\n",
    "nn.add(Dense(units=number_output_neurons, activation=\"sigmoid\"))\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "# Display the Sequential model summary\r\n",
    "nn.summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 6)                 60        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 28        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 10        \n",
      "=================================================================\n",
      "Total params: 98\n",
      "Trainable params: 98\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 2: Compile and fit the model using the `binary_crossentropy` loss function, the `adam` optimizer, and the `accuracy` evaluation metric.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "# Compile the Sequential model\r\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "# Fit the model using 50 epochs and the training data\r\n",
    "model = nn.fit(X_train_scaled, y_train, epochs=50, verbose=0)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 3: Evaluate the model using the test data to determine the model’s loss and accuracy.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "# Evaluate the model loss and accuracy metrics using the evaluate method and the test data\r\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled, y_test, verbose=True)\r\n",
    "\r\n",
    "# Display the model loss and accuracy results\r\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "116/116 [==============================] - 0s 375us/step - loss: 8.3040e-08 - accuracy: 0.9973\n",
      "Loss: 8.303999976533305e-08, Accuracy: 0.9973045587539673\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 4: Save and export your model to an HDF5 file"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "# Set the model's file path\r\n",
    "filename = \"DLNN_model_1\"\r\n",
    "file_path = Path('Resources/' + filename + '.h5')\r\n",
    "\r\n",
    "# Export your model to a HDF5 file\r\n",
    "nn.save(file_path)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "## Optimize the neural network model\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 1: Define at least three new deep neural network models (resulting in the original plus 3 optimization attempts). With each, try to improve on your first model’s predictive accuracy.\n",
    "\n",
    "> **Rewind** Recall that perfect accuracy has a value of 1, so accuracy improves as its value moves closer to 1. To optimize your model for a predictive accuracy as close to 1 as possible, you can use any or all of the following techniques:\n",
    ">\n",
    "> * Adjust the input data by dropping different features columns to ensure that no variables or outliers confuse the model.\n",
    ">\n",
    "> * Add more neurons (nodes) to a hidden layer.\n",
    ">\n",
    "> * Add more hidden layers.\n",
    ">\n",
    "> * Use different activation functions for the hidden layers.\n",
    ">\n",
    "> * Add to or reduce the number of epochs in the training regimen.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Alternative Model 1 - Deep learning model with 2 hidden layers"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "# Define the the number of inputs (features) to the model\r\n",
    "number_input_features = len(X_train.iloc[0])\r\n",
    "print(number_input_features)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "9\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "# Review the number of features\r\n",
    "number_input_features"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "# Define the number of neurons in the output layer\r\n",
    "number_output_neurons_A1 = 2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "# Define the number of hidden nodes for the first hidden layer\r\n",
    "hidden_nodes_layer1_A1 =  int(round((number_input_features + number_output_neurons_A1)/2, 0))\r\n",
    "# Review the number hidden nodes in the first layer\r\n",
    "hidden_nodes_layer1_A1\r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "# Define the number of hidden nodes for the second hidden layer\r\n",
    "hidden_nodes_layer2_A1 =  int(round((hidden_nodes_layer1_A1 + number_output_neurons_A1)/2, 0))\r\n",
    "\r\n",
    "# Review the number hidden nodes in the second layer\r\n",
    "hidden_nodes_layer2_A1\r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "# Define the number of hidden nodes for the second hidden layer\r\n",
    "hidden_nodes_layer3_A1 =  int(round((hidden_nodes_layer2_A1 + number_output_neurons_A1)/2, 0))\r\n",
    "\r\n",
    "# Review the number hidden nodes in the second layer\r\n",
    "hidden_nodes_layer3_A1\r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "# Create the Sequential model instance\r\n",
    "nn_A1 = Sequential()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "# Add the first hidden layer\r\n",
    "nn_A1.add(Dense(units=hidden_nodes_layer1_A1, activation=\"relu\", input_dim=number_input_features))\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "# Add the second hidden layer\r\n",
    "nn_A1.add(Dense(units=hidden_nodes_layer2_A1, activation=\"relu\"))\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "# Add the second hidden layer\r\n",
    "nn_A1.add(Dense(units=hidden_nodes_layer3_A1, activation=\"relu\"))\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "# Add the output layer to the model specifying the number of output neurons and activation function\r\n",
    "nn_A1.add(Dense(units=number_output_neurons_A1, activation=\"sigmoid\"))\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "# Display the Sequential model summary\r\n",
    "nn_A1.summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 6)                 60        \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 4)                 28        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 3)                 15        \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2)                 8         \n",
      "=================================================================\n",
      "Total params: 111\n",
      "Trainable params: 111\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "# Compile the Sequential model\r\n",
    "nn_A1.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "# Fit the model using 50 epochs and the training data\r\n",
    "model_A1 = nn_A1.fit(X_train_scaled, y_train, epochs=50, verbose=0)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Alternative Model 2 - Deep learning model with 3 hidden layers"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "# Define the the number of inputs (features) to the model\r\n",
    "number_input_features = len(X_train.iloc[0])\r\n",
    "print(number_input_features)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "9\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "# Review the number of features\r\n",
    "number_input_features"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "# Define the number of neurons in the output layer\r\n",
    "number_output_neurons_A2 = 2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "source": [
    "# Define the number of hidden nodes for the first hidden layer\r\n",
    "hidden_nodes_layer1_A2 =  int(round((number_input_features + number_output_neurons_A2)/2, 0))\r\n",
    "# Review the number hidden nodes in the first layer\r\n",
    "hidden_nodes_layer1_A2\r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "metadata": {},
     "execution_count": 47
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "# Define the number of hidden nodes for the second hidden layer\r\n",
    "hidden_nodes_layer2_A2 =  int(round((hidden_nodes_layer1_A2 + number_output_neurons_A2)/2, 0))\r\n",
    "\r\n",
    "# Review the number hidden nodes in the second layer\r\n",
    "hidden_nodes_layer2_A2\r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [
    "# Define the number of hidden nodes for the second hidden layer\r\n",
    "hidden_nodes_layer3_A2 =  int(round((hidden_nodes_layer2_A1 + number_output_neurons_A2)/2, 0))\r\n",
    "\r\n",
    "# Review the number hidden nodes in the second layer\r\n",
    "hidden_nodes_layer3_A2\r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "source": [
    "# Define the number of hidden nodes for the second hidden layer\r\n",
    "hidden_nodes_layer4_A2 =  int(round((hidden_nodes_layer3_A1 + number_output_neurons_A2)/2, 0))\r\n",
    "\r\n",
    "# Review the number hidden nodes in the second layer\r\n",
    "hidden_nodes_layer4_A2\r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "source": [
    "# Create the Sequential model instance\r\n",
    "nn_A2 = Sequential()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "source": [
    "# Add the first hidden layer\r\n",
    "nn_A2.add(Dense(units=hidden_nodes_layer1_A2, activation=\"relu\", input_dim=number_input_features))\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "source": [
    "# Add the second hidden layer\r\n",
    "nn_A2.add(Dense(units=hidden_nodes_layer2_A2, activation=\"relu\"))\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "source": [
    "# Add the second hidden layer\r\n",
    "nn_A2.add(Dense(units=hidden_nodes_layer3_A2, activation=\"relu\"))\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "source": [
    "# Add the second hidden layer\r\n",
    "nn_A2.add(Dense(units=hidden_nodes_layer4_A2, activation=\"relu\"))\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "source": [
    "# Add the output layer to the model specifying the number of output neurons and activation function\r\n",
    "nn_A2.add(Dense(units=number_output_neurons_A2, activation=\"sigmoid\"))\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "source": [
    "# Display the Sequential model summary\r\n",
    "nn_A2.summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 6)                 60        \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 4)                 28        \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 3)                 15        \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 2)                 8         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 2)                 6         \n",
      "=================================================================\n",
      "Total params: 117\n",
      "Trainable params: 117\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "source": [
    "# Compile the Sequential model\r\n",
    "nn_A2.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "source": [
    "# Fit the model using 50 epochs and the training data\r\n",
    "model_A2 = nn_A2.fit(X_train_scaled, y_train, epochs=50, verbose=0)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Alternative Model 3 - Principal Component Analysis"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "source": [
    "from sklearn.decomposition import PCA\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "source": [
    "# Create a StandardScaler instance\r\n",
    "pca_scaler = StandardScaler()\r\n",
    "\r\n",
    "# Fit the scaler to the features\r\n",
    "X_pca_scaler = pca_scaler.fit(X)\r\n",
    "\r\n",
    "# Fit the scaler to the features\r\n",
    "X_pca_scaled = X_pca_scaler.transform(X)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "source": [
    "# for n in range(2, number_input_features):\r\n",
    "best_n = number_input_features\r\n",
    "for n in range(number_input_features, 2, -1):\r\n",
    "    pca = PCA(n_components=n, random_state=1)\r\n",
    "    X_pca = pca.fit_transform(X_pca_scaled)\r\n",
    "    exp_var = pca.explained_variance_ratio_\r\n",
    "#     print(f'{exp_var}')\r\n",
    "    print(f'N = {n:3}: Total explained variance: {100*exp_var.sum():.4f}%')\r\n",
    "    if exp_var.sum() > .999:\r\n",
    "        best_n = n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "N =   9: Total explained variance: 100.0000%\n",
      "N =   8: Total explained variance: 100.0000%\n",
      "N =   7: Total explained variance: 99.9998%\n",
      "N =   6: Total explained variance: 99.9987%\n",
      "N =   5: Total explained variance: 99.9968%\n",
      "N =   4: Total explained variance: 87.5497%\n",
      "N =   3: Total explained variance: 75.0507%\n"
     ]
    }
   ],
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "source": [
    "print(best_n)\r\n",
    "pca = PCA(n_components=best_n, random_state=1)\r\n",
    "X_pca = pca.fit_transform(X_pca_scaled)\r\n",
    "exp_var = pca.explained_variance_ratio_\r\n",
    "print(f'N = {best_n:3}: Total explained variance: {100*exp_var.sum():.4f}%')\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "9\n",
      "N =   9: Total explained variance: 100.0000%\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_pca_train, X_pca_test, y_pca_train, y_pca_test = train_test_split(X_pca, y, random_state=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Define the the number of inputs (features) to the model\r\n",
    "number_input_features = best_n\r\n",
    "print(number_input_features)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "13\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Define the number of neurons in the output layer\r\n",
    "number_output_neurons_A3 = 2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Define the number of hidden nodes for the first hidden layer\r\n",
    "hidden_nodes_layer1_A3 =  int(round((number_input_features + number_output_neurons_A3)/2, 0))\r\n",
    "# Review the number hidden nodes in the first layer\r\n",
    "hidden_nodes_layer1_A3\r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "metadata": {},
     "execution_count": 66
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Define the number of hidden nodes for the second hidden layer\r\n",
    "hidden_nodes_layer2_A3 =  int(round((hidden_nodes_layer1_A3 + number_output_neurons_A3)/2, 0))\r\n",
    "\r\n",
    "# Review the number hidden nodes in the second layer\r\n",
    "hidden_nodes_layer2_A3\r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "metadata": {},
     "execution_count": 67
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Define the number of hidden nodes for the third hidden layer\r\n",
    "hidden_nodes_layer3_A3 =  int(round((hidden_nodes_layer2_A3 + number_output_neurons_A3)/2, 0))\r\n",
    "\r\n",
    "# Review the number hidden nodes in the third layer\r\n",
    "hidden_nodes_layer3_A3\r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "metadata": {},
     "execution_count": 68
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create the Sequential model instance\r\n",
    "nn_A3 = Sequential()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Add the first hidden layer\r\n",
    "nn_A3.add(Dense(units=hidden_nodes_layer1_A3, activation=\"relu\", input_dim=number_input_features))\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Add the second hidden layer\r\n",
    "nn_A3.add(Dense(units=hidden_nodes_layer2_A3, activation=\"relu\"))\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Add the third hidden layer\r\n",
    "nn_A3.add(Dense(units=hidden_nodes_layer3_A3, activation=\"relu\"))\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Add the output layer to the model specifying the number of output neurons and activation function\r\n",
    "nn_A3.add(Dense(units=number_output_neurons_A3, activation=\"sigmoid\"))\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Display the Sequential model summary\r\n",
    "nn_A3.summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 8)                 112       \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 5)                 45        \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 4)                 24        \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 2)                 10        \n",
      "=================================================================\n",
      "Total params: 191\n",
      "Trainable params: 191\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Compile the Sequential model\r\n",
    "nn_A3.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Fit the model using 50 epochs and the training data\r\n",
    "model_A3 = nn_A3.fit(X_pca_train, y_pca_train, epochs=50, verbose=1)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/50\n",
      "293/293 [==============================] - 0s 476us/step - loss: 0.3251 - accuracy: 0.8975\n",
      "Epoch 2/50\n",
      "293/293 [==============================] - 0s 475us/step - loss: 0.1694 - accuracy: 0.9153\n",
      "Epoch 3/50\n",
      "293/293 [==============================] - 0s 465us/step - loss: 0.1578 - accuracy: 0.9202\n",
      "Epoch 4/50\n",
      "293/293 [==============================] - 0s 471us/step - loss: 0.1544 - accuracy: 0.9206\n",
      "Epoch 5/50\n",
      "293/293 [==============================] - 0s 465us/step - loss: 0.1524 - accuracy: 0.9197\n",
      "Epoch 6/50\n",
      "293/293 [==============================] - 0s 465us/step - loss: 0.1508 - accuracy: 0.9184\n",
      "Epoch 7/50\n",
      "293/293 [==============================] - 0s 468us/step - loss: 0.1485 - accuracy: 0.9160\n",
      "Epoch 8/50\n",
      "293/293 [==============================] - 0s 488us/step - loss: 0.1466 - accuracy: 0.9136\n",
      "Epoch 9/50\n",
      "293/293 [==============================] - 0s 505us/step - loss: 0.1451 - accuracy: 0.9136\n",
      "Epoch 10/50\n",
      "293/293 [==============================] - 0s 472us/step - loss: 0.1439 - accuracy: 0.9136\n",
      "Epoch 11/50\n",
      "293/293 [==============================] - 0s 461us/step - loss: 0.1431 - accuracy: 0.9132\n",
      "Epoch 12/50\n",
      "293/293 [==============================] - 0s 461us/step - loss: 0.1422 - accuracy: 0.9132\n",
      "Epoch 13/50\n",
      "293/293 [==============================] - 0s 465us/step - loss: 0.1417 - accuracy: 0.9129\n",
      "Epoch 14/50\n",
      "293/293 [==============================] - 0s 461us/step - loss: 0.1413 - accuracy: 0.9133\n",
      "Epoch 15/50\n",
      "293/293 [==============================] - 0s 461us/step - loss: 0.1405 - accuracy: 0.9134\n",
      "Epoch 16/50\n",
      "293/293 [==============================] - 0s 461us/step - loss: 0.1401 - accuracy: 0.9132\n",
      "Epoch 17/50\n",
      "293/293 [==============================] - 0s 461us/step - loss: 0.1398 - accuracy: 0.9133\n",
      "Epoch 18/50\n",
      "293/293 [==============================] - 0s 461us/step - loss: 0.1396 - accuracy: 0.9133\n",
      "Epoch 19/50\n",
      "293/293 [==============================] - 0s 461us/step - loss: 0.1393 - accuracy: 0.9131\n",
      "Epoch 20/50\n",
      "293/293 [==============================] - 0s 461us/step - loss: 0.1388 - accuracy: 0.9131\n",
      "Epoch 21/50\n",
      "293/293 [==============================] - 0s 458us/step - loss: 0.1389 - accuracy: 0.9129\n",
      "Epoch 22/50\n",
      "293/293 [==============================] - 0s 461us/step - loss: 0.1385 - accuracy: 0.9132\n",
      "Epoch 23/50\n",
      "293/293 [==============================] - 0s 458us/step - loss: 0.1382 - accuracy: 0.9132\n",
      "Epoch 24/50\n",
      "293/293 [==============================] - 0s 482us/step - loss: 0.1380 - accuracy: 0.9131\n",
      "Epoch 25/50\n",
      "293/293 [==============================] - 0s 461us/step - loss: 0.1382 - accuracy: 0.9130\n",
      "Epoch 26/50\n",
      "293/293 [==============================] - 0s 458us/step - loss: 0.1381 - accuracy: 0.9127\n",
      "Epoch 27/50\n",
      "293/293 [==============================] - 0s 458us/step - loss: 0.1375 - accuracy: 0.9132\n",
      "Epoch 28/50\n",
      "293/293 [==============================] - 0s 458us/step - loss: 0.1376 - accuracy: 0.9133\n",
      "Epoch 29/50\n",
      "293/293 [==============================] - 0s 458us/step - loss: 0.1374 - accuracy: 0.9130\n",
      "Epoch 30/50\n",
      "293/293 [==============================] - 0s 458us/step - loss: 0.1376 - accuracy: 0.9133\n",
      "Epoch 31/50\n",
      "293/293 [==============================] - 0s 461us/step - loss: 0.1371 - accuracy: 0.9130\n",
      "Epoch 32/50\n",
      "293/293 [==============================] - 0s 461us/step - loss: 0.1372 - accuracy: 0.9131\n",
      "Epoch 33/50\n",
      "293/293 [==============================] - 0s 461us/step - loss: 0.1370 - accuracy: 0.9131\n",
      "Epoch 34/50\n",
      "293/293 [==============================] - 0s 461us/step - loss: 0.1369 - accuracy: 0.9128\n",
      "Epoch 35/50\n",
      "293/293 [==============================] - 0s 461us/step - loss: 0.1370 - accuracy: 0.9131\n",
      "Epoch 36/50\n",
      "293/293 [==============================] - 0s 458us/step - loss: 0.1369 - accuracy: 0.9133\n",
      "Epoch 37/50\n",
      "293/293 [==============================] - 0s 461us/step - loss: 0.1368 - accuracy: 0.9136\n",
      "Epoch 38/50\n",
      "293/293 [==============================] - 0s 461us/step - loss: 0.1366 - accuracy: 0.9136\n",
      "Epoch 39/50\n",
      "293/293 [==============================] - 0s 461us/step - loss: 0.1362 - accuracy: 0.9130\n",
      "Epoch 40/50\n",
      "293/293 [==============================] - 0s 461us/step - loss: 0.1366 - accuracy: 0.9130\n",
      "Epoch 41/50\n",
      "293/293 [==============================] - 0s 482us/step - loss: 0.1364 - accuracy: 0.9131\n",
      "Epoch 42/50\n",
      "293/293 [==============================] - 0s 495us/step - loss: 0.1362 - accuracy: 0.9131\n",
      "Epoch 43/50\n",
      "293/293 [==============================] - 0s 471us/step - loss: 0.1360 - accuracy: 0.9140\n",
      "Epoch 44/50\n",
      "293/293 [==============================] - 0s 461us/step - loss: 0.1360 - accuracy: 0.9137\n",
      "Epoch 45/50\n",
      "293/293 [==============================] - 0s 458us/step - loss: 0.1357 - accuracy: 0.9130\n",
      "Epoch 46/50\n",
      "293/293 [==============================] - 0s 461us/step - loss: 0.1359 - accuracy: 0.9137\n",
      "Epoch 47/50\n",
      "293/293 [==============================] - 0s 471us/step - loss: 0.1358 - accuracy: 0.9136\n",
      "Epoch 48/50\n",
      "293/293 [==============================] - 0s 509us/step - loss: 0.1358 - accuracy: 0.9135\n",
      "Epoch 49/50\n",
      "293/293 [==============================] - 0s 488us/step - loss: 0.1357 - accuracy: 0.9135\n",
      "Epoch 50/50\n",
      "293/293 [==============================] - 0s 485us/step - loss: 0.1351 - accuracy: 0.9132\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 2: After finishing your models, display the accuracy scores achieved by each model, and compare the results."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Original Model Results\")\r\n",
    "\r\n",
    "# Evaluate the model loss and accuracy metrics using the evaluate method and the test data\r\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled, y_test, verbose=True)\r\n",
    "\r\n",
    "# Display the model loss and accuracy results\r\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Original Model Results\n",
      "98/98 [==============================] - 0s 397us/step - loss: 0.1395 - accuracy: 0.9089\n",
      "Loss: 0.13953788578510284, Accuracy: 0.9089452028274536\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Alternative Model 1 Results\")\r\n",
    "\r\n",
    "# Evaluate the model loss and accuracy metrics using the evaluate method and the test data\r\n",
    "model_loss, model_accuracy = nn_A1.evaluate(X_test_scaled, y_test, verbose=True)\r\n",
    "\r\n",
    "# Display the model loss and accuracy results\r\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Alternative Model 1 Results\n",
      "98/98 [==============================] - 0s 391us/step - loss: 0.1365 - accuracy: 0.9093\n",
      "Loss: 0.13650137186050415, Accuracy: 0.9092658162117004\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Alternative Model 2 Results\")\r\n",
    "\r\n",
    "# Evaluate the model loss and accuracy metrics using the evaluate method and the test data\r\n",
    "model_loss, model_accuracy = nn_A2.evaluate(X_test_scaled, y_test, verbose=True)\r\n",
    "\r\n",
    "# Display the model loss and accuracy results\r\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Alternative Model 2 Results\n",
      "98/98 [==============================] - 0s 385us/step - loss: 0.1399 - accuracy: 0.9093\n",
      "Loss: 0.13988523185253143, Accuracy: 0.9092658162117004\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Alternative Model 3 Results\")\r\n",
    "\r\n",
    "# Evaluate the model loss and accuracy metrics using the evaluate method and the test data\r\n",
    "model_loss, model_accuracy = nn_A3.evaluate(X_pca_test, y_pca_test, verbose=True)\r\n",
    "\r\n",
    "# Display the model loss and accuracy results\r\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Alternative Model 3 Results\n",
      "98/98 [==============================] - 0s 380us/step - loss: 0.1425 - accuracy: 0.9105\n",
      "Loss: 0.14249324798583984, Accuracy: 0.9105482697486877\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Run different numbers of epochs on best model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Fit the model using the training data with different numbers of epochs\r\n",
    "model_list = []\r\n",
    "for n in range(50, 151, 20):\r\n",
    "    print(f'Fitting model, epochs: {n}')\r\n",
    "    model_list.append(nn_A1.fit(X_train_scaled, y_train, epochs=50, verbose=False))\r\n",
    "#     model_A1 = nn_A1.fit(X_train_scaled, y_train, epochs=50, verbose=False)\r\n",
    "\r\n",
    "    # Evaluate the model loss and accuracy metrics using the evaluate method and the test data\r\n",
    "    model_loss, model_accuracy = nn_A1.evaluate(X_test_scaled, y_test, verbose=True)\r\n",
    "    # Display the model loss and accuracy results\r\n",
    "    print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")    "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting model, epochs: 50\n",
      "98/98 [==============================] - 0s 391us/step - loss: 0.1350 - accuracy: 0.9093\n",
      "Loss: 0.13496015965938568, Accuracy: 0.9092658162117004\n",
      "Fitting model, epochs: 70\n",
      "98/98 [==============================] - 0s 386us/step - loss: 0.1352 - accuracy: 0.9089\n",
      "Loss: 0.13516975939273834, Accuracy: 0.9089452028274536\n",
      "Fitting model, epochs: 90\n",
      "98/98 [==============================] - 0s 381us/step - loss: 0.1346 - accuracy: 0.9093\n",
      "Loss: 0.13464869558811188, Accuracy: 0.9092658162117004\n",
      "Fitting model, epochs: 110\n",
      "98/98 [==============================] - 0s 412us/step - loss: 0.1351 - accuracy: 0.9083\n",
      "Loss: 0.13511475920677185, Accuracy: 0.9083039164543152\n",
      "Fitting model, epochs: 130\n",
      "98/98 [==============================] - 0s 404us/step - loss: 0.1358 - accuracy: 0.9089\n",
      "Loss: 0.13577121496200562, Accuracy: 0.9089452028274536\n",
      "Fitting model, epochs: 150\n",
      "98/98 [==============================] - 0s 418us/step - loss: 0.1373 - accuracy: 0.9086\n",
      "Loss: 0.13730131089687347, Accuracy: 0.908624529838562\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# for model in model_list:\r\n",
    "#     pass\r\n",
    "#     print(model.history)\r\n",
    "    # Evaluate the model loss and accuracy metrics using the evaluate method and the test data\r\n",
    "#     model_loss, model_accuracy = nn.evaluate(X_test_scaled, y_test, verbose=True)\r\n",
    "    # Display the model loss and accuracy results\r\n",
    "#     print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 3: Save each of your alternative models as an HDF5 file.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Set the file path for the first alternative model\r\n",
    "filename = \"DLNN_model_A1\"\r\n",
    "file_path_A1 = Path('Resources/' + filename + '.h5')\r\n",
    "\r\n",
    "# Export your model to a HDF5 file\r\n",
    "nn_A1.save(file_path_A1)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Set the file path for the second alternative model\r\n",
    "filename = \"DLNN_model_A2\"\r\n",
    "file_path_A2 = Path('Resources/' + filename + '.h5')\r\n",
    "\r\n",
    "# Export your model to a HDF5 file\r\n",
    "nn_A2.save(file_path_A2)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# # Set the file path for the third alternative model\r\n",
    "filename = \"DLNN_model_A3\"\r\n",
    "file_path_A3 = Path('Resources/' + filename + '.h5')\r\n",
    "\r\n",
    "# # Export your model to a HDF5 file\r\n",
    "nn_A3.save(file_path_A3)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('algo': conda)"
  },
  "interpreter": {
   "hash": "d4156aaab05991101c6a751683038476f3e64298aad0394e408e9e53044404ee"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}